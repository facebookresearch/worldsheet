{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/ronghanghu/workspace/mmf_nr\n"
     ]
    }
   ],
   "source": [
    "cd ~/workspace/mmf_nr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "# from PIL import Image\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "# from torchvision.transforms import Compose, Normalize, Resize, ToTensor\n",
    "from mmf.datasets.builders.synsin_realestate10k.geometry import get_deltas\n",
    "\n",
    "\n",
    "class RealEstate10K(data.Dataset):\n",
    "    \"\"\" Dataset for loading the RealEstate10K. In this case, images are randomly\n",
    "    chosen within a video subject to certain constraints: e.g. they should\n",
    "    be within a number of frames but the angle and translation should\n",
    "    vary as much as possible.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, dataset, opts=None, num_views=2, seed=0, vectorize=False\n",
    "    ):\n",
    "        self.imageset = np.loadtxt(\n",
    "            opts.video_list,\n",
    "            dtype=np.str,\n",
    "        )\n",
    "\n",
    "        if dataset == \"train\":\n",
    "            self.imageset = self.imageset[0 : int(0.8 * self.imageset.shape[0])]\n",
    "        else:\n",
    "            self.imageset = self.imageset[int(0.8 * self.imageset.shape[0]) :]\n",
    "\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        self.base_file = opts.train_data_path\n",
    "\n",
    "        self.num_views = num_views\n",
    "        self.W = opts.W\n",
    "\n",
    "        self.dataset = \"train\"\n",
    "\n",
    "        self.ANGLE_THRESH = 5\n",
    "        self.TRANS_THRESH = 0.15\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imageset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index = self.rng.randint(self.imageset.shape[0])\n",
    "        # index = index % self.imageset.shape[0]\n",
    "        # Load text file containing frame information\n",
    "        frames = np.loadtxt(\n",
    "            self.base_file + \"/%s.txt\" % self.imageset[index]\n",
    "        )\n",
    "\n",
    "        image_index = self.rng.choice(frames.shape[0], size=(1,))[0]\n",
    "\n",
    "        # Chose 15 images within 30 frames of the iniital one\n",
    "        image_indices = self.rng.randint(80, size=(30,)) - 40 + image_index\n",
    "        image_indices = np.minimum(\n",
    "            np.maximum(image_indices, 0), frames.shape[0] - 1\n",
    "        )\n",
    "\n",
    "        # Look at the change in angle and choose a hard one\n",
    "        angles = []\n",
    "        translations = []\n",
    "        for viewpoint in range(0, image_indices.shape[0]):\n",
    "            orig_viewpoint = frames[image_index, 7:].reshape(3, 4)\n",
    "            new_viewpoint = frames[image_indices[viewpoint], 7:].reshape(3, 4)\n",
    "            dang, dtrans = get_deltas(orig_viewpoint, new_viewpoint)\n",
    "\n",
    "            angles += [dang]\n",
    "            translations += [dtrans]\n",
    "\n",
    "        angles = np.array(angles)\n",
    "        translations = np.array(translations)\n",
    "\n",
    "        mask = image_indices[\n",
    "            (angles > self.ANGLE_THRESH) | (translations > self.TRANS_THRESH)\n",
    "        ]\n",
    "\n",
    "        all_intrinsics = []\n",
    "        all_extrinsics = []\n",
    "        video_inds = []\n",
    "        frame_inds = []\n",
    "        for i in range(0, self.num_views):\n",
    "            if i == 0:\n",
    "                t_index = image_index\n",
    "            elif mask.shape[0] > 5:\n",
    "                # Choose a harder angle change\n",
    "                t_index = mask[self.rng.randint(mask.shape[0])]\n",
    "            else:\n",
    "                t_index = image_indices[\n",
    "                    self.rng.randint(image_indices.shape[0])\n",
    "                ]\n",
    "            \n",
    "            video_inds.append(self.imageset[index])\n",
    "            frame_inds.append(str(int(frames[t_index, 0])))\n",
    "\n",
    "            intrinsics = frames[t_index, 1:7] * self.W\n",
    "            extrinsics = frames[t_index, 7:]\n",
    "\n",
    "            all_intrinsics.append(intrinsics)\n",
    "            all_extrinsics.append(extrinsics)\n",
    "\n",
    "        return {\n",
    "            \"all_intrinsics\": all_intrinsics,\n",
    "            \"all_extrinsics\": all_extrinsics,\n",
    "            \"video_inds\": video_inds,\n",
    "            \"frame_inds\": frame_inds,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynSinDatasetOption:\n",
    "    def __init__(self, data_path, video_list, image_size):\n",
    "        self.W = image_size\n",
    "        self.train_data_path = data_path\n",
    "        self.video_list = video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = SynSinDatasetOption(\n",
    "    \"/checkpoint/ronghanghu/neural_rendering_datasets/realestate10K/RealEstate10K/frames/train/\",\n",
    "    \"/checkpoint/ronghanghu/neural_rendering_datasets/realestate10K/RealEstate10K/frames/train/video_loc.txt\",\n",
    "    256\n",
    ")\n",
    "\n",
    "dataset = RealEstate10K(\"val\", opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for idx in range(len(dataset)):\n",
    "    entry = dataset[idx]\n",
    "    assert entry['video_inds'][0] == entry['video_inds'][1]\n",
    "    video_id = entry['video_inds'][0]\n",
    "    frame_id_0, frame_id_1 = entry['frame_inds']\n",
    "    assert np.all(entry['all_intrinsics'][0] == entry['all_intrinsics'][1])\n",
    "    intrinsics = [str(x) for x in entry['all_intrinsics'][0][:4]]\n",
    "    extrinsics_0 = [str(x) for x in entry['all_extrinsics'][0]]\n",
    "    extrinsics_1 = [str(x) for x in entry['all_extrinsics'][1]]\n",
    "\n",
    "    all_strs = [video_id, frame_id_0, frame_id_1] + intrinsics + extrinsics_0 + extrinsics_1\n",
    "    line = ' '.join(all_strs) + '\\n'\n",
    "    lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and take the first 5000\n",
    "np.random.seed(3)\n",
    "np.random.shuffle(lines)\n",
    "val_lines = lines[:5000]\n",
    "val_lines.sort()\n",
    "\n",
    "with open(\"mmf/datasets/builders/synsin_realestate10k/realestate_val5000.txt\", \"w\") as f:\n",
    "    f.writelines(val_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
