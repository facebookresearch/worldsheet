{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/checkpoint/ronghanghu/neural_rendering_datasets/synsin_replica/{}/data'\n",
    "SAVE_IMDB_FILE = '/checkpoint/ronghanghu/pythia/data/datasets/synsin_habitat/defaults/annotations/imdb_replica_{}.npy'\n",
    "\n",
    "for split in ['test_jitter_angle20']:\n",
    "    print('processing split replica {}'.format(split))\n",
    "    data_files = glob(os.path.join(DATA_DIR.format(split), '*.npz'))\n",
    "    data_files = sorted(data_files)\n",
    "\n",
    "    imdb = [{'dataset': 'synsin_replica', 'split': split}]\n",
    "    for file in data_files:\n",
    "        basename = os.path.basename(file)\n",
    "        info = {\n",
    "            'image_id': basename.split('.')[0],\n",
    "            'data_path': '{}/data/{}'.format(split, basename),\n",
    "            'image_path_template': '{}/images/{}_im_%04d.jpg'.format(split, basename.split('.')[0]),\n",
    "        }\n",
    "        imdb.append(info)\n",
    "\n",
    "    print('got {} images'.format(len(imdb) - 1))\n",
    "    np.save(SAVE_IMDB_FILE.format(split), imdb)\n",
    "#     if 'train' in split:\n",
    "#         np.save(SAVE_IMDB_FILE.format('mini_' + split), imdb[0:1] + imdb[1::1000])\n",
    "#     else:\n",
    "#         np.save(SAVE_IMDB_FILE.format('mini_' + split), imdb[0:1] + imdb[1::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/checkpoint/ronghanghu/neural_rendering_datasets/synsin_mp3d/{}/data'\n",
    "SAVE_IMDB_FILE = '/checkpoint/ronghanghu/pythia/data/datasets/synsin_habitat/defaults/annotations/imdb_mp3d_{}.npy'\n",
    "\n",
    "for split in ['val_jitter_angle20', 'test_jitter_angle20']:\n",
    "    print('processing split mp3d {}'.format(split))\n",
    "    data_files = glob(os.path.join(DATA_DIR.format(split), '*.npz'))\n",
    "    data_files = sorted(data_files)\n",
    "\n",
    "    imdb = [{'dataset': 'synsin_mp3d', 'split': split}]\n",
    "    for file in data_files:\n",
    "        basename = os.path.basename(file)\n",
    "        info = {\n",
    "            'image_id': basename.split('.')[0],\n",
    "            'data_path': '{}/data/{}'.format(split, basename),\n",
    "            'image_path_template': '{}/images/{}_im_%04d.jpg'.format(split, basename.split('.')[0]),\n",
    "        }\n",
    "        imdb.append(info)\n",
    "\n",
    "    print('got {} images'.format(len(imdb) - 1))\n",
    "    np.save(SAVE_IMDB_FILE.format(split), imdb)\n",
    "#     if 'train' in split:\n",
    "#         np.save(SAVE_IMDB_FILE.format('mini_' + split), imdb[0:1] + imdb[1::1000])\n",
    "#     else:\n",
    "#         np.save(SAVE_IMDB_FILE.format('mini_' + split), imdb[0:1] + imdb[1::100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
